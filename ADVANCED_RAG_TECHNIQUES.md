# Advanced RAG Techniques Implementation

‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö RAG Chatbot ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

## üìö ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤

### 1. üéØ Re-Ranking with Cross-Encoder

**‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**
- ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ top-10 chunks ‡∏î‡πâ‡∏ß‡∏¢ Hybrid Search (BM25 + Vector)
- ‡πÉ‡∏ä‡πâ Cross-Encoder ‡πÄ‡∏û‡∏∑‡πà‡∏≠ re-rank ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å top-3-5 ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- Cross-Encoder ‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á query ‡πÅ‡∏•‡∏∞ document ‡πÅ‡∏ö‡∏ö pairwise

**‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:**
- ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å context ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- ‚úÖ ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á irrelevant context ‡πÉ‡∏´‡πâ LLM
- ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á context precision ‡πÅ‡∏•‡∏∞ faithfulness

**Model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:**
- `cross-encoder/ms-marco-MiniLM-L-6-v2` - ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ
- ‡∏≠‡∏µ‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: `BAAI/bge-reranker-base` (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤)

**‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge base ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ re-ranker
kb = HybridKnowledgeBase(use_reranker=True)

# ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ re-ranker
kb = HybridKnowledgeBase(use_reranker=False)
```

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:**
1. Hybrid Search ‡∏Ñ‡∏∑‡∏ô 15 documents (top_k_for_rerank)
2. Cross-Encoder ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì relevance score ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ document
3. Sort ‡∏ï‡∏≤‡∏° rerank_score ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å top-5
4. ‡∏™‡πà‡∏á top-5 ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡πÉ‡∏´‡πâ LLM

---

### 2. üóúÔ∏è Context Compression

**‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**
- ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ chunk ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ LLM ‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
- ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏Å ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

**‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:**
- ‚úÖ ‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô tokens ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LLM (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢)
- ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á context quality ‡πÅ‡∏•‡∏∞ signal-to-noise ratio
- ‚úÖ ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ LLM focus ‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏£‡∏¥‡∏á‡πÜ
- ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° answer relevancy ‡πÅ‡∏•‡∏∞ faithfulness

**‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á chatbot ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ compression
chatbot = GeminiChatbot(api_key, kb, use_compression=True)

# ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ compression
chatbot = GeminiChatbot(api_key, kb, use_compression=False)
```

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:**
1. LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞ context ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
2. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (YES) ‚Üí LLM ‡∏™‡∏Å‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)
3. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (NO) ‚Üí ‡∏ï‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á
4. ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ compressed context ‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

---

### 3. üîí Strict RAG Prompt Engineering

**‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏é‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏≤ ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÄ‡∏≠‡∏á (No Hallucination)

**‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:**
- ‚úÖ ‡∏•‡∏î hallucination (‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≠‡∏°)
- ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° faithfulness (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)
- ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á source-grounded accuracy
- ‚úÖ LLM ‡∏à‡∏∞‡∏ö‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ ‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏î‡∏≤

**‡∏Å‡∏é‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô Prompt:**
```
1. ‚úÖ ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á" ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‚ùå ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ
3. ‚ùå ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏°‡∏≤‡∏ï‡∏≠‡∏ö
4. ‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ
5. ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡∏ö‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
- ‚ùå "‡∏Ñ‡∏ì‡∏∞‡∏Ñ‡∏£‡∏∏‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£..." (‡πÄ‡∏î‡∏≤‡πÄ‡∏≠‡∏á)
- ‚úÖ "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏µ‡πà 02-555-2000 ‡∏Ñ‡πà‡∏∞"

---

### 4. üìä RAG Evaluation with Ragas

**‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**
- Framework ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö RAG ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- ‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ 4 metrics ‡∏´‡∏•‡∏±‡∏Å

**Metrics:**

#### 4.1 Context Precision (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á Context)
- ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤ context ‡∏ó‡∏µ‡πà retrieve ‡∏°‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á = context ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏à‡∏£‡∏¥‡∏á

#### 4.2 Context Recall (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ç‡∏≠‡∏á Context)
- ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤ context ‡∏ó‡∏µ‡πà retrieve ‡∏°‡∏≤‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á = context ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

#### 4.3 Faithfulness (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏ï‡∏¢‡πå‡∏ï‡πà‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)
- ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà LLM ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ ‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å context ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á = LLM ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏° context ‡πÑ‡∏°‡πà‡πÄ‡∏î‡∏≤

#### 4.4 Answer Relevancy (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö)
- ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á = ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡πÑ‡∏°‡πà‡∏≠‡πâ‡∏≠‡∏°‡∏Ñ‡πâ‡∏≠‡∏°

**‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**
```bash
# ‡∏£‡∏±‡∏ô evaluation
python evaluate_rag.py

# ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö configurations ‡∏ï‡πà‡∏≤‡∏á‡πÜ
python evaluate_rag.py --compare
```

---

## üöÄ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies
```bash
pip install -r requirements.txt
```

### ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö Full Stack (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
```python
from chatbot import HybridKnowledgeBase, GeminiChatbot
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv('GEMINI_API_KEY')

# ‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge base ‡∏û‡∏£‡πâ‡∏≠‡∏° re-ranker
kb = HybridKnowledgeBase(use_reranker=True)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á chatbot ‡∏û‡∏£‡πâ‡∏≠‡∏° context compression
chatbot = GeminiChatbot(api_key, kb, use_compression=True)

# ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
response = chatbot.chat("‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡πÇ‡∏¢‡∏ò‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏µ‡πà‡∏õ‡∏µ")
print(response)
```

### ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö Baseline (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á)
```python
# ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ re-ranker ‡πÅ‡∏•‡∏∞ compression
kb = HybridKnowledgeBase(use_reranker=False)
chatbot = GeminiChatbot(api_key, kb, use_compression=False)
```

---

## üìà ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ:

1. **Context Precision ‚Üë** - context ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
2. **Context Recall ‚Üë** - context ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
3. **Faithfulness ‚Üë** - LLM ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏° context ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡∏•‡∏î hallucination
4. **Answer Relevancy ‚Üë** - ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Configurations

```
Configuration 1: Baseline
‚îú‚îÄ‚îÄ Re-ranker: ‚ùå
‚îú‚îÄ‚îÄ Compression: ‚ùå
‚îî‚îÄ‚îÄ Metrics: Baseline scores

Configuration 2: With Re-ranker
‚îú‚îÄ‚îÄ Re-ranker: ‚úÖ
‚îú‚îÄ‚îÄ Compression: ‚ùå
‚îî‚îÄ‚îÄ Metrics: Improved context precision

Configuration 3: Full Stack (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
‚îú‚îÄ‚îÄ Re-ranker: ‚úÖ
‚îú‚îÄ‚îÄ Compression: ‚úÖ
‚îî‚îÄ‚îÄ Metrics: Best overall performance
```

---

## üîß ‡∏Å‡∏≤‡∏£ Tune Parameters

### Re-ranking Parameters
```python
# ‡πÉ‡∏ô search_knowledge() method
top_k_for_rerank = min(n_results * 3, 15)  # ‡πÄ‡∏Å‡πá‡∏ö 3x ‡πÑ‡∏ß‡πâ re-rank

# ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ re-rank ‡∏à‡∏≤‡∏Å pool ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô
top_k_for_rerank = min(n_results * 5, 20)
```

### Compression Parameters
```python
# ‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô compress_context()
# ‡∏õ‡∏£‡∏±‡∏ö prompt ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
compression_prompt = """..."""

# ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏Å‡∏±‡∏î
"‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 3-5 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
```

### Hybrid Search Weights
```python
# ‡πÉ‡∏ô main() function
kb.search_knowledge(
    query,
    n_results=8,
    bm25_weight=0.4,    # ‡∏õ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å BM25
    vector_weight=0.6   # ‡∏õ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å Vector Search
)
```

---

## üéØ Best Practices

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Baseline** - ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏Å‡πà‡∏≠‡∏ô
2. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß** - ‡∏î‡∏π‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ
3. **Evaluate ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠** - ‡πÉ‡∏ä‡πâ Ragas ‡∏ß‡∏±‡∏î‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
4. **Monitor Cost** - Context Compression ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î tokens ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡πÄ‡∏û‡∏¥‡πà‡∏°
5. **Balance Speed vs Quality** - Re-ranking ‡πÅ‡∏•‡∏∞ Compression ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô

---

## üêõ Troubleshooting

### Re-ranker ‡πÇ‡∏´‡∏•‡∏î‡∏ä‡πâ‡∏≤
```python
# ‡πÉ‡∏ä‡πâ model ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')  # ‡πÄ‡∏£‡πá‡∏ß
# ‡πÅ‡∏ó‡∏ô
self.reranker = CrossEncoder('BAAI/bge-reranker-large')  # ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏ï‡πà‡πÅ‡∏°‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤
```

### Context Compression ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô
```python
# ‡∏õ‡∏¥‡∏î compression ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
chatbot = GeminiChatbot(api_key, kb, use_compression=False)

# ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô contexts ‡∏ó‡∏µ‡πà compress
relevant_knowledge = kb.search_knowledge(query, n_results=5)  # ‡πÅ‡∏ó‡∏ô 8
```

### Ragas Evaluation Failed
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏Ñ‡∏£‡∏ö
pip install ragas langchain langchain-community datasets

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API key
export GEMINI_API_KEY="your-api-key"
```

---

## üìö ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á

- [Ragas Documentation](https://docs.ragas.io/)
- [Cross-Encoder for Re-ranking](https://www.sbert.net/examples/applications/cross-encoder/README.html)
- [LangChain Contextual Compression](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/)
- [RAG Best Practices](https://www.llamaindex.ai/blog/a-guide-to-rag-evaluation-metrics-d1a8f3d98ef5)

---

## ü§ù Contributing

‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤:
1. ‡πÄ‡∏õ‡∏¥‡∏î Issue ‡πÉ‡∏ô GitHub
2. ‡∏™‡πà‡∏á Pull Request ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
3. ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢
