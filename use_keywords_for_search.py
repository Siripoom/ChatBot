#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ keywords ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞ Vector Database
"""

import json
from typing import List, Dict

def load_keywords(json_file: str) -> Dict:
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• keywords ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON"""
    with open(json_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def get_top_keywords_by_file(data: Dict, top_n: int = 20) -> Dict[str, List[str]]:
    """
    ‡∏î‡∏∂‡∏á top N keywords ‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå

    Returns:
        Dictionary ‡∏ó‡∏µ‡πà‡∏°‡∏µ filename ‡πÄ‡∏õ‡πá‡∏ô key ‡πÅ‡∏•‡∏∞ list ‡∏Ç‡∏≠‡∏á keywords ‡πÄ‡∏õ‡πá‡∏ô value
    """
    result = {}
    for filename, file_data in data['files'].items():
        keywords = [kw['word'] for kw in file_data['keywords'][:top_n]]
        result[filename] = keywords
    return result

def create_metadata_for_vector_db(data: Dict, top_n: int = 30) -> List[Dict]:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vector Database

    ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏∞‡∏°‡∏µ metadata ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
    - filename: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
    - keywords: keywords ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    - top_keywords: top N keywords ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    - text_length: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
    - keyword_categories: ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤‡∏à‡∏≤‡∏Å keywords
    """
    metadata_list = []

    for filename, file_data in data['files'].items():
        # ‡∏î‡∏∂‡∏á keywords
        all_keywords = [kw['word'] for kw in file_data['keywords']]
        top_keywords = all_keywords[:top_n]

        # ‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏à‡∏≤‡∏Å keywords
        categories = categorize_by_keywords(top_keywords)

        metadata = {
            'filename': filename,
            'text_length': file_data['text_length'],
            'total_keywords': file_data['total_keywords'],
            'keywords': all_keywords,
            'top_keywords': top_keywords,
            'categories': categories,
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á string ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö full-text search
            'keywords_text': ' '.join(top_keywords)
        }

        metadata_list.append(metadata)

    return metadata_list

def categorize_by_keywords(keywords: List[str]) -> List[str]:
    """
    ‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏à‡∏≤‡∏Å keywords
    """
    categories = []

    # ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡πÇ‡∏¢‡∏ò‡∏≤
    civil_keywords = {'‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡πÇ‡∏¢‡∏ò‡∏≤', '‡πÇ‡∏¢‡∏ò‡∏≤', '‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á', '‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö', '‡∏á‡∏≤‡∏ô'}
    if any(kw in civil_keywords for kw in keywords):
        categories.append('‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡πÇ‡∏¢‡∏ò‡∏≤')

    # ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå/‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ
    cs_keywords = {'‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå', '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', '‡∏£‡∏∞‡∏ö‡∏ö', '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•', 'software', 'development'}
    if any(kw in cs_keywords for kw in keywords):
        categories.append('‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå/‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ')

    # ‡∏ß‡∏¥‡∏ä‡∏≤‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    general_keywords = {'‡∏ß‡∏¥‡∏ä‡∏≤‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ', '‡∏ó‡∏±‡∏Å‡∏©‡∏∞', '‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©', '‡∏™‡∏±‡∏á‡∏Ñ‡∏°', '‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à'}
    if any(kw in general_keywords for kw in keywords):
        categories.append('‡∏ß‡∏¥‡∏ä‡∏≤‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ')

    # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤
    student_keywords = {'‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤', '‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô', '‡∏™‡∏≠‡∏ö', '‡∏Ç‡πâ‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö', '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤'}
    if any(kw in student_keywords for kw in keywords):
        categories.append('‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤')

    # ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£
    curriculum_keywords = {'‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£', '‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï', '‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö', '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'}
    if any(kw in curriculum_keywords for kw in keywords):
        categories.append('‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£')

    return categories if categories else ['‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ']

def search_by_keyword(data: Dict, search_term: str, top_n: int = 3) -> List[Dict]:
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ keyword ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö search_term

    Returns:
        List ‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
    """
    results = []

    for filename, file_data in data['files'].items():
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà keyword ‡∏õ‡∏£‡∏≤‡∏Å‡∏è
        score = 0
        matched_keywords = []

        for kw_data in file_data['keywords']:
            keyword = kw_data['word']
            frequency = kw_data['frequency']

            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö partial match
            if search_term.lower() in keyword.lower() or keyword.lower() in search_term.lower():
                score += frequency
                matched_keywords.append({
                    'keyword': keyword,
                    'frequency': frequency
                })

        if score > 0:
            results.append({
                'filename': filename,
                'score': score,
                'matched_keywords': matched_keywords
            })

    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
    results.sort(key=lambda x: x['score'], reverse=True)

    return results[:top_n]

def get_related_keywords(data: Dict, keyword: str, top_n: int = 10) -> List[str]:
    """
    ‡∏´‡∏≤ keywords ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö keyword ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
    ‡πÇ‡∏î‡∏¢‡∏î‡∏π‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ keyword ‡∏ô‡∏±‡πâ‡∏ô‡∏õ‡∏£‡∏≤‡∏Å‡∏è
    """
    related = set()

    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ keyword
    for filename, file_data in data['files'].items():
        has_keyword = False

        for kw_data in file_data['keywords']:
            if keyword.lower() in kw_data['word'].lower():
                has_keyword = True
                break

        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ keyword ‡∏î‡∏∂‡∏á keywords ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏±‡πâ‡∏ô
        if has_keyword:
            for kw_data in file_data['keywords'][:top_n]:
                if keyword.lower() not in kw_data['word'].lower():
                    related.add(kw_data['word'])

    return list(related)[:top_n]

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == "__main__":
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    keywords_file = "/home/siripoom/chatbot/data/keywords_analysis.json"
    data = load_keywords(keywords_file)

    print("="*80)
    print("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Keywords ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
    print("="*80)

    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vector Database
    print("\n1Ô∏è‚É£  ‡∏™‡∏£‡πâ‡∏≤‡∏á Metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vector Database")
    print("-"*80)
    metadata_list = create_metadata_for_vector_db(data, top_n=20)

    for i, meta in enumerate(metadata_list, 1):
        print(f"\nüìÑ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà {i}: {meta['filename']}")
        print(f"   ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: {', '.join(meta['categories'])}")
        print(f"   Top Keywords: {', '.join(meta['top_keywords'][:5])}...")

    # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ keyword
    print("\n\n2Ô∏è‚É£  ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Keyword")
    print("-"*80)

    search_terms = ["‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå", "‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°", "‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤"]

    for term in search_terms:
        print(f"\nüîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '{term}'")
        results = search_by_keyword(data, term, top_n=3)

        for i, result in enumerate(results, 1):
            print(f"   {i}. {result['filename']}")
            print(f"      ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {result['score']}")
            print(f"      Keywords ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á: {', '.join([kw['keyword'] for kw in result['matched_keywords'][:3]])}")

    # 3. ‡∏´‡∏≤ related keywords
    print("\n\n3Ô∏è‚É£  ‡∏´‡∏≤ Keywords ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")
    print("-"*80)

    target_keywords = ["‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå", "‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°"]

    for keyword in target_keywords:
        related = get_related_keywords(data, keyword, top_n=8)
        print(f"\nüìå Keywords ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö '{keyword}':")
        print(f"   {', '.join(related)}")

    # 4. Export metadata ‡πÄ‡∏õ‡πá‡∏ô JSON
    print("\n\n4Ô∏è‚É£  Export Metadata")
    print("-"*80)

    output_file = "/home/siripoom/chatbot/data/vector_db_metadata.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(metadata_list, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vector DB ‡∏ó‡∏µ‡πà: {output_file}")

    print("\n" + "="*80)
    print("‚ú® ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
    print("="*80)
